---
author: Mariano Alcaniz Raya
year: "2020"
doi: 10.3389/fnhum.2020.00090
keyword1: "[[ASD]]"
keyword2: "[[VR]]"
keyword3: "[[Sensory processing]]"
keyword4: "[[Electrodermal activity (EDA)]]"
---
# Background

>[[ADOS]]’ unreliable outcomes and affect the truthfulness of responses is the social desirability bias (Paulhus, 1991). Social desirability is a response bias in which individuals attempt to answer to tasks or questions in a manner that will be viewed as favorable by others (Edwards, 1957)

>Finally, although diagnostic structured interviews are considered as the gold standard in [[ASD]] assessment (Goldstein et al., 2009), they usually take place in the laboratory rather than in ecologically valid settings. [[Ecologically valid settings]] are environments and situations similar to real ones, able to elicit everyday experiences and behaviors related to daily functioning (Franzen and Wilhelm, 1996; Chaytor et al., 2006). The more the assessment measure is valid from an ecological point of view, the more that the results can be generalized to the real world

>([[DSM-5]], [[ICD]], [[ADOS]], and [[ADIR]]) do not consider quantitative variations in symptom severity in each person’s measurements and do not take into account the biological bases of the disorder

>the emerging field of [[Computational Psychiatry]] (CP) is seeking, first,  to mathematically model brain responses to the problems it faces and, second, to study how the “abnormal” experiences, emotions, and behaviors that are commonly used to describe disorders contribute to normal function and neural processes (Montague et al., 2012; Friston et al., 2014; Wang and Krystal, 2014; Redish and Gordon, 2016).

>In [[ASD]], the study of gaze activity measured by [[Eye-tracking]] tools was analyzed as behavioral tests, linking the gaze patterns to the existence of nuclear deficits

>The evidence from these studies are controversial: some research found no differences in [[Electrodermal activity (EDA)]] levels in response to sensory stimuli (e.g., Zahn et al., 1987; Rogers and Ozonoff, 2005; McCormick et al., 2014), whereas other studies were successful (van Engeland et al., 1991; Miller et al., 2001; Rogers and Ozonoff, 2005; Schoen et al., 2009).

>The use of [[VR]] in [[ASD]] research has been postulated as one of the methods with great potential in the treatment of the main symptomatological nucleus (Wing et al., 2011; Parsons T. D., 2016; Golestan et al., 2018)
# Objectives

>no one has investigated whether multimodal [[VR]] settings and EDA reactions might contribute to predicting [[ASD]] population versus [[Typically developed (TD)]] children. Starting from these premises, we performed two studies (the first exploratory and the second confirmatory) to discriminate and predict sensory processing in the [[ASD]] population versus in a [[Typically developed (TD)]] population through the combined use of implicit measure (EDA) and different sensory stimuli, involving two different [[Virtual environment]] and tasks. To this extent, the first experiment aimed to analyze the influence of three factors in predicting [[ASD]]: (1) the VE contents, one VE including a relaxing environment and another one including an [[Arousal]] environment; (2) the task, one related to the subject’s greeting responses in the relaxing environment and others related to the subject’s imitation in the arousal environment; and (3) the stimuli conditions (SC), including visual (V), visual and auditive (VA), and visual, auditive, and olfactive stimuli (VAO)

>Starting from these premises and aims, the first hypothesis in experiment 1 was that the [[ASD]] recognition is higher in the forest since the response to a greeting is one of the confirmatory symptoms in the [[ASD]]. The second hypothesis was that, by including more sensory modalities, the [[ASD]] recognition using EDA would present a better performance. After that, we performed a second experiment in order to develop a supervised learning model using the outputs of the first experiment. We increased the number of subjects used to calibrate the model and we tested it in a set of subjects not used before, simulating a real-world application.

# Experimental Design & Procedure

>The environment was developed and projected inside a three-surface Cave Assisted Virtual Environment (CAVETM) with dimensions of 4 m × 4 m × 3 m.

>Two VEs were developed:  1. A virtual forest, including three controlled stimuli conditions: visual, visual–auditive, and visual–auditiveolfactive (Figure 3). The visual stimuli consisted of a girl’s avatar appearing from the left side of the forest and walking to the central virtual scene, where she stopped and waved her hand three times to say hello to the child, and then leaving the virtual scene, walking to the right side of the forest (Figure 4). The auditive stimuli consisted of adding to the virtual forest a storm and rain sound. Finally, the olfactive stimuli consisted of an odor of fresh-cut grass.  2. The other VE involved a simulated city street intersection (Figure 5) and was divided into three experimental stimuli conditions: visual, visual–auditive, and visual–auditiveolfactive. First, in the V stimuli condition, a boy’s avatar appeared from the left side of the surface CAVETM, walking to the center of the virtual scene, where he stopped and waved his hand three times to say hello to the child, and then leaving the virtual scene, walking out of the street intersection (Figure 6). Successively, a girl’s avatar appeared in the central of the surface CAVETM, walking to the right of the virtual scene, where she stopped and repeated the three waves with her hand to say hello to the child, and then leaving the virtual scene, walking to the right side of the street intersection. This sequence was repeated three times. In the second VA stimuli condition, the same avatars appeared in the same order from the same directions, but instead of waving the hand to say hello, they danced over a piece of music for 10 s for three times. In the VAO stimuli condition, the same avatars appeared in the same order and from the same directions, but they bit a buttered muffin, accompanied by the same song of the previous condition and an artificial butter smell that was released during the VR experience.

>Before each stimuli condition, 2 min of EDA baseline was recorded in rest and relaxing state, and then the VE experiences started

>1-week rest between the two experimental sessions
# Participants

[[ADOS]]
>In the study, the assessment was performed using module 1, corresponding to children from 31 months of age who do not use phrase language consistently

>The study included 52 children between the ages of 4 and 7 years. In detail, 23 TD children (age = 4.87 ± 0.92; male = 13, female = 10) and 29 children with a previous diagnosis of [[ASD]] (age = 5.20 ± 1.34; male = 26, female = 3) participated in experiment 1
# Measures


# Results

>the model developed using the forest VE presented a higher accuracy (forest VE—all, 90.3%) than the model developed using the city VE (city VE—all, 70.59%)
>...
>This outcome could be due to task characteristics since the response to a greeting is one of the confirmatory symptoms in [[ASD]]. In addition, several previous studies showed the influence of nature scenes in reducing arousal
>...
>In addition to the increase of arousal derived from city VE, the avatars imitation task provoked a physical activity in the subject that could affect arousal, decreasing the recognition performance

# Conclusion

>the inclusion of core symptom analyses in VR is suggested, for example, repetitive and stereotypical behaviors, and communication and social abilities. Biomarkers that could be relevant for this purpose are eye tracking, body movement analysis, and EEG (Loth et al., 2016); indeed eye tracking glasses and RGBD cameras for body movement analysis might be included in future studies on current VR experiences in order to enhance model strength and accuracy

>[[ASD]] show hyper-sensitiveness (overresponsiveness) to VA stimuli and hypo-sensitiveness (underresponsiveness) to olfactive stimuli

>it is possible to obtain biomarkers for [[ASD]] classification using a CP paradigm based on implicit brain processes, measured through psychophysiological signals and the subjects’ behavior, while exposed to complex social conditions using VR interfaces

# Images

![[Pasted image 20251202104242.png]]

![[Pasted image 20251202095328.png]]

![[Pasted image 20251202095305.png]]